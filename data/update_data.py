#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í•˜ë‚˜ì¹´ë“œ ë°ì´í„° ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- consulting_date: 2025ë…„ 8ì›” 1ì¼ ~ 9ì›” 12ì¼ ë¶„ë°°
- consulting_time: ì˜¤ì „ 9ì‹œ ~ ì˜¤í›„ 6ì‹œ ëœë¤ ë¶„ë°°
- ìƒë‹´ ê±´ìˆ˜: ì´ˆë°˜ ì¼ 100~150ê±´ â†’ í›„ë°˜ ì¼ 200~300ê±´ìœ¼ë¡œ ì¦ê°€
"""

import json
import os
import random
from datetime import datetime, timedelta
from pathlib import Path

def generate_date_distribution(total_files=7267):
    """
    ìƒë‹´ ê±´ìˆ˜ë¥¼ ë‚ ì§œë³„ë¡œ ë¶„ë°°
    - ì´ˆë°˜: ì¼ 100~150ê±´
    - í›„ë°˜: ì¼ 200~300ê±´ìœ¼ë¡œ ì¦ê°€
    """
    start_date = datetime(2025, 8, 1)
    end_date = datetime(2025, 9, 12)
    total_days = (end_date - start_date).days + 1
    
    # ë‚ ì§œë³„ ìƒë‹´ ê±´ìˆ˜ ë¶„ë°° (ì ì§„ì  ì¦ê°€)
    daily_counts = {}
    current_date = start_date
    
    for i in range(total_days):
        # ì´ˆë°˜ì—ëŠ” ì ê²Œ, í›„ë°˜ì—ëŠ” ë§ê²Œ
        progress = i / total_days
        if progress < 0.3:  # ì´ˆë°˜ 30%
            base_count = 100 + int(progress * 100)  # 100~130
        elif progress < 0.7:  # ì¤‘ë°˜ 40%
            base_count = 130 + int((progress - 0.3) * 150)  # 130~190
        else:  # í›„ë°˜ 30%
            base_count = 190 + int((progress - 0.7) * 110)  # 190~300
        
        # ëœë¤ ë³€ë™ ì¶”ê°€ (Â±20%)
        variation = random.uniform(0.8, 1.2)
        daily_counts[current_date.strftime('%Y-%m-%d')] = max(1, int(base_count * variation))
        current_date += timedelta(days=1)
    
    # ì´ ê±´ìˆ˜ê°€ ë§ë„ë¡ ì¡°ì •
    total_allocated = sum(daily_counts.values())
    if total_allocated != total_files:
        # ê°€ì¥ ë§ì€ ë‚ ì§œì—ì„œ ì¡°ì •
        max_date = max(daily_counts, key=daily_counts.get)
        daily_counts[max_date] += (total_files - total_allocated)
    
    return daily_counts

def generate_time_distribution():
    """
    ìƒë‹´ ì‹œê°„ ë¶„ë°° (ì˜¤ì „ 9ì‹œ ~ ì˜¤í›„ 6ì‹œ)
    - ì—…ë¬´ ì‹œê°„ëŒ€ì— ì§‘ì¤‘
    """
    # ì‹œê°„ëŒ€ë³„ ê°€ì¤‘ì¹˜ (ì—…ë¬´ ì‹œê°„ì— ì§‘ì¤‘)
    time_weights = {
        '09:00': 0.8, '09:30': 1.0, '10:00': 1.2, '10:30': 1.3,
        '11:00': 1.4, '11:30': 1.5, '12:00': 1.6, '12:30': 1.4,
        '13:00': 1.2, '13:30': 1.1, '14:00': 1.3, '14:30': 1.4,
        '15:00': 1.5, '15:30': 1.6, '16:00': 1.7, '16:30': 1.8,
        '17:00': 1.9, '17:30': 1.7, '18:00': 1.2
    }
    
    # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ëœë¤ ì„ íƒ
    times = list(time_weights.keys())
    weights = list(time_weights.values())
    return random.choices(times, weights=weights)[0]

def update_json_file(file_path, file_index, daily_counts):
    """
    JSON íŒŒì¼ ì—…ë°ì´íŠ¸
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if not data or not isinstance(data, list) or len(data) == 0:
            print(f"âš ï¸  {file_path}: ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° í˜•ì‹")
            return False
        
        # ë‚ ì§œ í• ë‹¹
        assigned_date = None
        for date_str, count in daily_counts.items():
            if count > 0:
                assigned_date = date_str
                daily_counts[date_str] -= 1
                break
        
        if not assigned_date:
            print(f"âŒ {file_path}: ë‚ ì§œ í• ë‹¹ ì‹¤íŒ¨")
            return False
        
        # ì‹œê°„ ìƒì„±
        consulting_time = generate_time_distribution()
        
        # ë°ì´í„° ì—…ë°ì´íŠ¸
        for item in data:
            if isinstance(item, dict):
                item['consulting_date'] = assigned_date
                item['consulting_time'] = consulting_time
        
        # íŒŒì¼ ì €ì¥
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent='\t')
        
        return True
        
    except Exception as e:
        print(f"âŒ {file_path} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    print("ğŸš€ í•˜ë‚˜ì¹´ë“œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘")
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
    data_dir = Path("data/01.ì›ì²œë°ì´í„°/TS_í•˜ë‚˜ì¹´ë“œ")
    
    if not data_dir.exists():
        print(f"âŒ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
        return
    
    # JSON íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
    json_files = sorted([f for f in data_dir.glob("*.json")], 
                        key=lambda x: int(x.stem.split('_')[1]) if x.stem.split('_')[1].isdigit() else 0)
    
    total_files = len(json_files)
    print(f"ğŸ“ ì´ {total_files}ê°œì˜ JSON íŒŒì¼ ë°œê²¬")
    
    # ë‚ ì§œ ë¶„ë°° ìƒì„±
    daily_counts = generate_date_distribution(total_files)
    print(f"ğŸ“… ë‚ ì§œë³„ ìƒë‹´ ê±´ìˆ˜ ë¶„ë°° ì™„ë£Œ (ì´ {sum(daily_counts.values())}ê±´)")
    
    # ìƒìœ„ 10ê°œ ë‚ ì§œ ì¶œë ¥
    print("\nğŸ“Š ìƒìœ„ 10ê°œ ë‚ ì§œë³„ ìƒë‹´ ê±´ìˆ˜:")
    sorted_daily = sorted(daily_counts.items(), key=lambda x: x[1], reverse=True)[:10]
    for date, count in sorted_daily:
        print(f"   {date}: {count}ê±´")
    
    # íŒŒì¼ë³„ ì—…ë°ì´íŠ¸
    success_count = 0
    error_count = 0
    
    print(f"\nğŸ”„ íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹œì‘...")
    
    for i, file_path in enumerate(json_files, 1):
        if update_json_file(file_path, i, daily_counts):
            success_count += 1
            if i % 100 == 0:
                print(f"   ì§„í–‰ë¥ : {i}/{total_files} ({i/total_files*100:.1f}%)")
        else:
            error_count += 1
    
    print(f"\nâœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
    print(f"   ì„±ê³µ: {success_count}ê°œ")
    print(f"   ì‹¤íŒ¨: {error_count}ê°œ")
    print(f"   ì´ íŒŒì¼: {total_files}ê°œ")
    
    # ìµœì¢… ë‚ ì§œ ë¶„ë°° í™•ì¸
    print(f"\nğŸ“Š ìµœì¢… ë‚ ì§œë³„ ìƒë‹´ ê±´ìˆ˜:")
    for date, count in sorted(daily_counts.items()):
        if count > 0:
            print(f"   {date}: {count}ê±´")

if __name__ == "__main__":
    main()
